{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Tensorflow_1_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilgautamin/Machine-Learning-/blob/master/CNN_Tensorflow_1_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUEvkapA3UmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "1549bcef-95ce-4ef1-8c6a-f4069c6c0260"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp6yFBwh4xsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4fbb829-fb63-4857-e888-cf2aa43bd310"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcDufuyw416O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a6c1424d-48c5-4632-b185-e2eae06c8ba6"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST\",one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-5d57e62475e4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijTq1ICv5Nfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define weights and biases\n",
        "def init_weights(shape):\n",
        "  init_random_dist = tf.truncated_normal(shape,stddev=0.1,seed=0)\n",
        "  return tf.Variable(init_random_dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7XhY5vR5i9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_bias(shape):\n",
        "  init_bias_vals = tf.constant(0.1,shape=shape)\n",
        "  return tf.Variable(init_bias_vals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80tsmmRi5yHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#W is the filter, x is the input images\n",
        "#x is basically 4d tensor\n",
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks-8TauN6ItO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pooling_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1,2,2,1],\n",
        "                        strides= [1,2,2,1],\n",
        "                        padding = 'SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16ehcWP6kmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_layer(input_x, shape):\n",
        "  W = init_weights(shape)\n",
        "  b = init_bias([shape[3]])\n",
        "  return tf.nn.relu(conv2d(input_x, W)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc0X-fRQ7D3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_full_layer(input_layer, size):\n",
        "  input_size = int(input_layer.get_shape()[1])\n",
        "  W = init_weights([input_size, size])\n",
        "  b = init_bias([size])\n",
        "  return tf.matmul(input_layer, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zDNufu-7gx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#placeholders\n",
        "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
        "y = tf.placeholder(tf.float32, shape = [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox81WjVb7z4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Flatteing the image and -1 will take its shape\n",
        "x_image = tf.reshape(x,[-1,28,28,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-AQuK-F8AMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#layer_1\n",
        "convo_1 = convolutional_layer(x_image, shape = [5,5,1,32])\n",
        "convo_1_pooling = max_pooling_2x2(convo_1)\n",
        "\n",
        "#layer_2\n",
        "convo_2 = convolutional_layer(convo_1_pooling, shape = [5,5,32,64])\n",
        "convo_2_pooling = max_pooling_2x2(convo_2)\n",
        "\n",
        "#flatten it out\n",
        "#28 / 2 = 14 / 2 = 7\n",
        "convo_2_flat = tf.reshape(convo_2_pooling, shape = [-1,7*7*64])\n",
        "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1064))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTgZf_tL9iPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropout\n",
        "hold_prob = tf.placeholder(tf.float32)\n",
        "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob = hold_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu2Ofdd0-gPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = normal_full_layer(full_layer_one, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjg3vJYs-nkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y,\n",
        "                                                                          logits = y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fA1hwBP-1bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7K3KyX4-_Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#init\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwkJf3MW_Ek_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c976ee6-80d8-4ee1-fbc5-34467026f2ea"
      },
      "source": [
        "steps = 10000\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "\n",
        "  for i in range(steps):\n",
        "    batch_x, batch_y = mnist.train.next_batch(300)\n",
        "    sess.run(train, feed_dict = {x:batch_x, y:batch_y, hold_prob:0.4})\n",
        "    if i%100 == 0:\n",
        "      matches = tf.equal(tf.arg_max(y_pred, 1), tf.arg_max(y,1))\n",
        "      acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
        "      print(\"Currently on step {}, Accuracy = \".format(i))\n",
        "      print(sess.run(acc,feed_dict = {x:mnist.test.images,\n",
        "                                      y:mnist.test.labels,\n",
        "                                      hold_prob:1.0}))      "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently on step 0, Accuracy = \n",
            "0.1719\n",
            "Currently on step 100, Accuracy = \n",
            "0.9495\n",
            "Currently on step 200, Accuracy = \n",
            "0.9779\n",
            "Currently on step 300, Accuracy = \n",
            "0.9814\n",
            "Currently on step 400, Accuracy = \n",
            "0.9858\n",
            "Currently on step 500, Accuracy = \n",
            "0.9818\n",
            "Currently on step 600, Accuracy = \n",
            "0.9871\n",
            "Currently on step 700, Accuracy = \n",
            "0.987\n",
            "Currently on step 800, Accuracy = \n",
            "0.9888\n",
            "Currently on step 900, Accuracy = \n",
            "0.9879\n",
            "Currently on step 1000, Accuracy = \n",
            "0.9882\n",
            "Currently on step 1100, Accuracy = \n",
            "0.9897\n",
            "Currently on step 1200, Accuracy = \n",
            "0.9897\n",
            "Currently on step 1300, Accuracy = \n",
            "0.989\n",
            "Currently on step 1400, Accuracy = \n",
            "0.9862\n",
            "Currently on step 1500, Accuracy = \n",
            "0.9883\n",
            "Currently on step 1600, Accuracy = \n",
            "0.9883\n",
            "Currently on step 1700, Accuracy = \n",
            "0.9901\n",
            "Currently on step 1800, Accuracy = \n",
            "0.9903\n",
            "Currently on step 1900, Accuracy = \n",
            "0.9882\n",
            "Currently on step 2000, Accuracy = \n",
            "0.988\n",
            "Currently on step 2100, Accuracy = \n",
            "0.9904\n",
            "Currently on step 2200, Accuracy = \n",
            "0.9896\n",
            "Currently on step 2300, Accuracy = \n",
            "0.9908\n",
            "Currently on step 2400, Accuracy = \n",
            "0.9908\n",
            "Currently on step 2500, Accuracy = \n",
            "0.9894\n",
            "Currently on step 2600, Accuracy = \n",
            "0.9908\n",
            "Currently on step 2700, Accuracy = \n",
            "0.99\n",
            "Currently on step 2800, Accuracy = \n",
            "0.9895\n",
            "Currently on step 2900, Accuracy = \n",
            "0.9902\n",
            "Currently on step 3000, Accuracy = \n",
            "0.9905\n",
            "Currently on step 3100, Accuracy = \n",
            "0.9891\n",
            "Currently on step 3200, Accuracy = \n",
            "0.9893\n",
            "Currently on step 3300, Accuracy = \n",
            "0.9913\n",
            "Currently on step 3400, Accuracy = \n",
            "0.9874\n",
            "Currently on step 3500, Accuracy = \n",
            "0.9889\n",
            "Currently on step 3600, Accuracy = \n",
            "0.9882\n",
            "Currently on step 3700, Accuracy = \n",
            "0.9893\n",
            "Currently on step 3800, Accuracy = \n",
            "0.9904\n",
            "Currently on step 3900, Accuracy = \n",
            "0.9893\n",
            "Currently on step 4000, Accuracy = \n",
            "0.9869\n",
            "Currently on step 4100, Accuracy = \n",
            "0.9904\n",
            "Currently on step 4200, Accuracy = \n",
            "0.9897\n",
            "Currently on step 4300, Accuracy = \n",
            "0.9911\n",
            "Currently on step 4400, Accuracy = \n",
            "0.9877\n",
            "Currently on step 4500, Accuracy = \n",
            "0.9916\n",
            "Currently on step 4600, Accuracy = \n",
            "0.99\n",
            "Currently on step 4700, Accuracy = \n",
            "0.9901\n",
            "Currently on step 4800, Accuracy = \n",
            "0.9898\n",
            "Currently on step 4900, Accuracy = \n",
            "0.9877\n",
            "Currently on step 5000, Accuracy = \n",
            "0.9904\n",
            "Currently on step 5100, Accuracy = \n",
            "0.9889\n",
            "Currently on step 5200, Accuracy = \n",
            "0.9911\n",
            "Currently on step 5300, Accuracy = \n",
            "0.9896\n",
            "Currently on step 5400, Accuracy = \n",
            "0.9909\n",
            "Currently on step 5500, Accuracy = \n",
            "0.993\n",
            "Currently on step 5600, Accuracy = \n",
            "0.9923\n",
            "Currently on step 5700, Accuracy = \n",
            "0.9929\n",
            "Currently on step 5800, Accuracy = \n",
            "0.9926\n",
            "Currently on step 5900, Accuracy = \n",
            "0.9912\n",
            "Currently on step 6000, Accuracy = \n",
            "0.991\n",
            "Currently on step 6100, Accuracy = \n",
            "0.9869\n",
            "Currently on step 6200, Accuracy = \n",
            "0.9885\n",
            "Currently on step 6300, Accuracy = \n",
            "0.9894\n",
            "Currently on step 6400, Accuracy = \n",
            "0.9896\n",
            "Currently on step 6500, Accuracy = \n",
            "0.9903\n",
            "Currently on step 6600, Accuracy = \n",
            "0.9882\n",
            "Currently on step 6700, Accuracy = \n",
            "0.9905\n",
            "Currently on step 6800, Accuracy = \n",
            "0.9892\n",
            "Currently on step 6900, Accuracy = \n",
            "0.9907\n",
            "Currently on step 7000, Accuracy = \n",
            "0.9909\n",
            "Currently on step 7100, Accuracy = \n",
            "0.9913\n",
            "Currently on step 7200, Accuracy = \n",
            "0.9916\n",
            "Currently on step 7300, Accuracy = \n",
            "0.9918\n",
            "Currently on step 7400, Accuracy = \n",
            "0.9921\n",
            "Currently on step 7500, Accuracy = \n",
            "0.9921\n",
            "Currently on step 7600, Accuracy = \n",
            "0.9921\n",
            "Currently on step 7700, Accuracy = \n",
            "0.992\n",
            "Currently on step 7800, Accuracy = \n",
            "0.992\n",
            "Currently on step 7900, Accuracy = \n",
            "0.9919\n",
            "Currently on step 8000, Accuracy = \n",
            "0.9919\n",
            "Currently on step 8100, Accuracy = \n",
            "0.992\n",
            "Currently on step 8200, Accuracy = \n",
            "0.992\n",
            "Currently on step 8300, Accuracy = \n",
            "0.9921\n",
            "Currently on step 8400, Accuracy = \n",
            "0.992\n",
            "Currently on step 8500, Accuracy = \n",
            "0.9921\n",
            "Currently on step 8600, Accuracy = \n",
            "0.9921\n",
            "Currently on step 8700, Accuracy = \n",
            "0.9921\n",
            "Currently on step 8800, Accuracy = \n",
            "0.992\n",
            "Currently on step 8900, Accuracy = \n",
            "0.992\n",
            "Currently on step 9000, Accuracy = \n",
            "0.992\n",
            "Currently on step 9100, Accuracy = \n",
            "0.992\n",
            "Currently on step 9200, Accuracy = \n",
            "0.9922\n",
            "Currently on step 9300, Accuracy = \n",
            "0.9922\n",
            "Currently on step 9400, Accuracy = \n",
            "0.9922\n",
            "Currently on step 9500, Accuracy = \n",
            "0.9923\n",
            "Currently on step 9600, Accuracy = \n",
            "0.9923\n",
            "Currently on step 9700, Accuracy = \n",
            "0.9923\n",
            "Currently on step 9800, Accuracy = \n",
            "0.9924\n",
            "Currently on step 9900, Accuracy = \n",
            "0.9924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUItlzJYKkSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}