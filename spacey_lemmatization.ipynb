{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "spacey_lemmatization.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilgautamin/Machine-Learning-/blob/master/spacey_lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTgsbbi1T1e2",
        "colab_type": "text"
      },
      "source": [
        "# Lemmatization\n",
        "In contrast to stemming, lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a *morphological analysis* to words. The lemma of 'was' is 'be' and the lemma of 'mice' is 'mouse'. Further, the lemma of 'meeting' might be 'meet' or 'meeting' depending on its use in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_8L8FizT1e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform standard imports:\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLxFhrG-T1e9",
        "colab_type": "code",
        "outputId": "b3120e8d-36a3-4e90-d54d-58974afeaefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "doc1 = nlp(u\"I am a runner running in a race because I love to run since i ran today\")\n",
        "for token in doc1:\n",
        "  print(token.text,'-->',token.lemma_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I --> -PRON-\n",
            "am --> be\n",
            "a --> a\n",
            "runner --> runner\n",
            "running --> run\n",
            "in --> in\n",
            "a --> a\n",
            "race --> race\n",
            "because --> because\n",
            "I --> -PRON-\n",
            "love --> love\n",
            "to --> to\n",
            "run --> run\n",
            "since --> since\n",
            "i --> i\n",
            "ran --> run\n",
            "today --> today\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQC4czvKT1fC",
        "colab_type": "text"
      },
      "source": [
        "<font color=green>In the above sentence, `running`, `run` and `ran` all point to the same lemma `run` (...11841) to avoid duplication.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlaQIop3T1fD",
        "colab_type": "text"
      },
      "source": [
        "### Function to display lemmas\n",
        "Since the display above is staggared and hard to read, let's write a function that displays the information we want more neatly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUXSaYfwT1fE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_lemmas(text):\n",
        "  for token in text:\n",
        "    print(f'{token.text:{12}} {token.pos_}{8} {token.lemma:>{22}} {token.lemma_}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QStnubH6T1fH",
        "colab_type": "text"
      },
      "source": [
        "Here we're using an **f-string** to format the printed text by setting minimum field widths and adding a left-align to the lemma hash value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNWxtog6T1fI",
        "colab_type": "code",
        "outputId": "20dc18a5-a08a-4d15-a8ae-021f3455a022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
        "show_lemmas(doc2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I            PRON8     561228191312463089 -PRON-\n",
            "saw          VERB8   11925638236994514241 see\n",
            "eighteen     NUM8    9609336664675087640 eighteen\n",
            "mice         NOUN8    1384165645700560590 mouse\n",
            "today        NOUN8   11042482332948150395 today\n",
            "!            PUNCT8   17494803046312582752 !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIRJRqmBT1fO",
        "colab_type": "text"
      },
      "source": [
        "<font color=green>Notice that the lemma of `saw` is `see`, `mice` is the plural form of `mouse`, and yet `eighteen` is its own number, *not* an expanded form of `eight`.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Z2JWW3T1fP",
        "colab_type": "code",
        "outputId": "e1401288-7b5f-40c6-dd23-20ba6ecfc37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "doc3 = nlp(u\"I am meeting him tomorrow at the meeting.\")\n",
        "show_lemmas(doc3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I            PRON6 561228191312463089     -PRON-\n",
            "am           VERB6 10382539506755952630   be\n",
            "meeting      VERB6 6880656908171229526    meet\n",
            "him          PRON6 561228191312463089     -PRON-\n",
            "tomorrow     NOUN6 3573583789758258062    tomorrow\n",
            "at           ADP6 11667289587015813222   at\n",
            "the          DET6 7425985699627899538    the\n",
            "meeting      NOUN6 14798207169164081740   meeting\n",
            ".            PUNCT6 12646065887601541794   .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYYMX-k6T1fT",
        "colab_type": "text"
      },
      "source": [
        "<font color=green>Here the lemma of `meeting` is determined by its Part of Speech tag.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwEQj0ovT1fU",
        "colab_type": "code",
        "outputId": "0548bbe3-4081-4863-8c1f-6a8016152886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "doc4 = nlp(u\"That's an enormous automobile\")\n",
        "show_lemmas(doc4)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "That         DET6 4380130941430378203    that\n",
            "'s           VERB6 10382539506755952630   be\n",
            "an           DET6 15099054000809333061   an\n",
            "enormous     ADJ6 17917224542039855524   enormous\n",
            "automobile   NOUN6 7211811266693931283    automobile\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBaOJdbjT1fX",
        "colab_type": "text"
      },
      "source": [
        "<font color=green>Note that lemmatization does *not* reduce words to their most basic synonym - that is, `enormous` doesn't become `big` and `automobile` doesn't become `car`.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrAyjQt5T1fY",
        "colab_type": "text"
      },
      "source": [
        "We should point out that although lemmatization looks at surrounding text to determine a given word's part of speech, it does not categorize phrases. In an upcoming lecture we'll investigate *word vectors and similarity*.\n"
      ]
    }
  ]
}